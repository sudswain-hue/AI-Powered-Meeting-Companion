{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Run this block first to install Openai Whisper\n",
        "!pip install streamlit git+https://github.com/openai/whisper.git transformers spacy\n",
        "!python -m spacy download en_core_web_sm\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "krcYVo4rPeBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#After getting Openai Whisper installed run this code block\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import whisper\n",
        "from transformers import pipeline\n",
        "import spacy\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "def transcript(audio_path):\n",
        "    model = whisper.load_model(\"base\")\n",
        "    result = model.transcribe(audio_path)\n",
        "    transcription_text = result[\"text\"]\n",
        "    return transcription_text\n",
        "\n",
        "def summary(transcription_text):\n",
        "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "    summary_output = summarizer(transcription_text, max_length=70, min_length=20, do_sample=False)\n",
        "    return summary_output[0]['summary_text']\n",
        "\n",
        "def action_items(transcription_text):\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    doc = nlp(transcription_text)\n",
        "    action_keywords = [\"please\", \"send\", \"review\", \"schedule\", \"complete\", \"update\", \"assign\", \"remind\"]\n",
        "\n",
        "    def is_action_item(sentence):\n",
        "        return any(keyword in sentence.text.lower() for keyword in action_keywords)\n",
        "\n",
        "    extracted_items = []\n",
        "    for sent in doc.sents:\n",
        "        if is_action_item(sent):\n",
        "            persons = [ent.text for ent in sent.ents if ent.label_ == \"PERSON\"]\n",
        "            deadlines = [ent.text for ent in sent.ents if ent.label_ in [\"DATE\", \"TIME\"]]\n",
        "            extracted_items.append({\n",
        "                \"task\": sent.text.strip(),\n",
        "                \"owners\": persons,\n",
        "                \"deadlines\": deadlines\n",
        "            })\n",
        "    return extracted_items\n",
        "\n",
        "def map_stars_to_sentiment(label):\n",
        "    stars = int(label.split()[0])\n",
        "    if stars <= 2:\n",
        "        return \"negative\"\n",
        "    elif stars == 3:\n",
        "        return \"neutral\"\n",
        "    else:\n",
        "        return \"positive\"\n",
        "\n",
        "def sentiment_analysis(transcription_text):\n",
        "    classifier = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "    sentences = [sentence.strip() for sentence in transcription_text.split('.') if sentence.strip()]\n",
        "    sentiment_results = []\n",
        "    for sentence in sentences:\n",
        "        result = classifier(sentence)[0]\n",
        "        sentiment = map_stars_to_sentiment(result[\"label\"])\n",
        "        sentiment_results.append({\n",
        "            \"text\": sentence,\n",
        "            \"label\": result[\"label\"],\n",
        "            \"score\": result[\"score\"],\n",
        "            \"sentiment\": sentiment\n",
        "        })\n",
        "    return sentiment_results\n",
        "\n",
        "def main():\n",
        "    st.set_page_config(layout=\"wide\")\n",
        "    st.title(\"MeetScribe\")\n",
        "\n",
        "    # Top section: Upload and transcript in two columns\n",
        "    top_left, top_right = st.columns([1, 2])\n",
        "\n",
        "    with top_left:\n",
        "        st.markdown(\"#### Upload Audio\")\n",
        "        uploaded_file = st.file_uploader(\"Upload the Audio file\",type=[\"mp3\", \"wav\", \"m4a\"])\n",
        "\n",
        "        if uploaded_file is not None:\n",
        "            # Save the file\n",
        "            with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_file.name)[1]) as tmp_file:\n",
        "                tmp_file.write(uploaded_file.read())\n",
        "                tmp_path = tmp_file.name\n",
        "\n",
        "            # Display audio player\n",
        "            st.audio(uploaded_file)\n",
        "\n",
        "    # Initialize variables\n",
        "    transcription_text = \"\"\n",
        "\n",
        "    # Display transcript in right column (always present)\n",
        "    with top_right:\n",
        "        st.markdown(\"#### Transcription\")\n",
        "        transcript_area = st.empty()\n",
        "        transcript_box = transcript_area.text_area(\"\", transcription_text, height=300,\n",
        "                                                  placeholder=\"Transcript will appear here...\")\n",
        "\n",
        "        # Download button container (initially empty)\n",
        "        download_btn_container = st.empty()\n",
        "\n",
        "    # Analysis results container\n",
        "    analysis_container = st.container()\n",
        "\n",
        "    # Processing logic\n",
        "    if uploaded_file is not None:\n",
        "        # Processing indicator\n",
        "        progress_placeholder = st.empty()\n",
        "        progress_placeholder.info(\"Transcribing audio...\")\n",
        "\n",
        "        # Process the audio file\n",
        "        transcription_text = transcript(tmp_path)\n",
        "        progress_placeholder.success(\"Transcription complete!\")\n",
        "\n",
        "        # Update transcript area\n",
        "        transcript_box = transcript_area.text_area(\"\", transcription_text, height=300)\n",
        "\n",
        "        # Add download button for transcript\n",
        "        download_btn_container.download_button(\n",
        "            label=\"Download Transcript\",\n",
        "            data=transcription_text,\n",
        "            file_name=\"transcript.txt\",\n",
        "            mime=\"text/plain\"\n",
        "        )\n",
        "\n",
        "        # Analysis section\n",
        "        with analysis_container:\n",
        "            st.markdown(\"---\")\n",
        "            st.markdown(\"### Analysis Results\")\n",
        "\n",
        "            # Create tabs for the analysis sections\n",
        "            tab1, tab2, tab3 = st.tabs([\"#### Summary\", \"#### Action Items\", \"#### Sentiment Analysis\"])\n",
        "\n",
        "            # Summary Tab\n",
        "            with tab1:\n",
        "                with st.spinner(\"Generating summary...\"):\n",
        "                    summary_text = summary(transcription_text)\n",
        "                    st.text_area(\"Meeting Summary\", summary_text, height=300)\n",
        "                    st.download_button(\n",
        "                        label=\"Download Summary\",\n",
        "                        data=summary_text,\n",
        "                        file_name=\"summary.txt\",\n",
        "                        mime=\"text/plain\"\n",
        "                    )\n",
        "\n",
        "            # Action Items Tab\n",
        "            with tab2:\n",
        "                with st.spinner(\"Extracting action items...\"):\n",
        "                    actions = action_items(transcription_text)\n",
        "                    if actions:\n",
        "                        action_text = \"\"\n",
        "\n",
        "                        for idx, item in enumerate(actions, 1):\n",
        "                            st.markdown(f\"**{idx}. Task:** {item['task']}\")\n",
        "                            st.markdown(f\"   **Assigned To:** {', '.join(item['owners']) if item['owners'] else 'N/A'}\")\n",
        "                            st.markdown(f\"   **Deadlines:** {', '.join(item['deadlines']) if item['deadlines'] else 'N/A'}\")\n",
        "                            st.markdown(\"   ---\")\n",
        "\n",
        "                            # Build text for download\n",
        "                            action_text += f\"{idx}. Task: {item['task']}\\n\"\n",
        "                            action_text += f\"   Assigned To: {', '.join(item['owners']) if item['owners'] else 'N/A'}\\n\"\n",
        "                            action_text += f\"   Deadlines: {', '.join(item['deadlines']) if item['deadlines'] else 'N/A'}\\n\\n\"\n",
        "\n",
        "                        if action_text:\n",
        "                            st.download_button(\n",
        "                                label=\"Download Action Items\",\n",
        "                                data=action_text,\n",
        "                                file_name=\"action_items.txt\",\n",
        "                                mime=\"text/plain\"\n",
        "                            )\n",
        "                    else:\n",
        "                        st.info(\"No action items found in this meeting recording.\")\n",
        "                        st.markdown(\"\"\"\n",
        "                        Action items are typically introduced with words like:\n",
        "                        - please\n",
        "                        - send\n",
        "                        - review\n",
        "                        - schedule\n",
        "                        - complete\n",
        "                        - update\n",
        "                        - assign\n",
        "                        - remind\n",
        "                        \"\"\")\n",
        "\n",
        "            # Sentiment Analysis Tab\n",
        "            with tab3:\n",
        "                with st.spinner(\"Performing sentiment analysis...\"):\n",
        "                    sentiments = sentiment_analysis(transcription_text)\n",
        "\n",
        "                    # Create metrics for sentiment stats\n",
        "                    pos_count = sum(1 for s in sentiments if s['sentiment'] == 'positive')\n",
        "                    neu_count = sum(1 for s in sentiments if s['sentiment'] == 'neutral')\n",
        "                    neg_count = sum(1 for s in sentiments if s['sentiment'] == 'negative')\n",
        "                    total = len(sentiments) if sentiments else 1  # Avoid division by zero\n",
        "\n",
        "                    # Display sentiment distribution\n",
        "                    st.markdown(\"#### Sentiment Distribution\")\n",
        "                    stat_cols = st.columns(3)\n",
        "                    with stat_cols[0]:\n",
        "                        st.metric(\"Positive\", f\"{pos_count} ({pos_count/total*100:.1f}%)\")\n",
        "                    with stat_cols[1]:\n",
        "                        st.metric(\"Neutral\", f\"{neu_count} ({neu_count/total*100:.1f}%)\")\n",
        "                    with stat_cols[2]:\n",
        "                        st.metric(\"Negative\", f\"{neg_count} ({neg_count/total*100:.1f}%)\")\n",
        "\n",
        "                    # Detailed sentiment results\n",
        "                    st.markdown(\"#### Detailed Sentiment Analysis\")\n",
        "                    sentiment_text = \"\"\n",
        "\n",
        "                    # Create a container with fixed height for detailed results\n",
        "                    detailed_sentiment = st.container()\n",
        "                    with detailed_sentiment:\n",
        "                        # Create an expander for each sentiment category\n",
        "                        if pos_count > 0:\n",
        "                            with st.expander(f\"Positive Statements ({pos_count})\"):\n",
        "                                for idx, result in enumerate(sentiments, 1):\n",
        "                                    if result['sentiment'] == 'positive':\n",
        "                                        st.markdown(f\"**{idx}. Text:** {result['text']}\")\n",
        "                                        st.markdown(f\"   **Score:** {result['score']:.2f}\")\n",
        "                                        st.markdown(\"   ---\")\n",
        "\n",
        "                        if neu_count > 0:\n",
        "                            with st.expander(f\"Neutral Statements ({neu_count})\"):\n",
        "                                for idx, result in enumerate(sentiments, 1):\n",
        "                                    if result['sentiment'] == 'neutral':\n",
        "                                        st.markdown(f\"**{idx}. Text:** {result['text']}\")\n",
        "                                        st.markdown(f\"   **Score:** {result['score']:.2f}\")\n",
        "                                        st.markdown(\"   ---\")\n",
        "\n",
        "                        if neg_count > 0:\n",
        "                            with st.expander(f\"Negative Statements ({neg_count})\"):\n",
        "                                for idx, result in enumerate(sentiments, 1):\n",
        "                                    if result['sentiment'] == 'negative':\n",
        "                                        st.markdown(f\"**{idx}. Text:** {result['text']}\")\n",
        "                                        st.markdown(f\"   **Score:** {result['score']:.2f}\")\n",
        "                                        st.markdown(\"   ---\")\n",
        "\n",
        "                    # Build text for download\n",
        "                    for idx, result in enumerate(sentiments, 1):\n",
        "                        sentiment_text += f\"{idx}. Text: {result['text']}\\n\"\n",
        "                        sentiment_text += f\"   Sentiment: {result['sentiment']} (Score: {result['score']:.2f})\\n\\n\"\n",
        "\n",
        "                    if sentiment_text:\n",
        "                        st.download_button(\n",
        "                            label=\"Download Sentiment Analysis\",\n",
        "                            data=sentiment_text,\n",
        "                            file_name=\"sentiment_analysis.txt\",\n",
        "                            mime=\"text/plain\"\n",
        "                        )\n",
        "\n",
        "  # Add signature at the bottom right\n",
        "    st.markdown(\"---\")\n",
        "    signature_col1, signature_col2 = st.columns([3, 1])\n",
        "    with signature_col2:\n",
        "        st.markdown(\"<div style='text-align: right; font-style: italic; color: #666;'>Developed by CodeBrew ðŸ¤–</div>\", unsafe_allow_html=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "CWfz-DMjmgZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Next run this code block to install pyngrok if you have not already\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "id": "SQcl9jYaQYgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this code block next. Notice the first link that it produces, that will be important for later.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from pyngrok import ngrok\n",
        "# Replace 'YOUR_AUTHTOKEN' with your actual Ngrok authtoken\n",
        "ngrok.set_auth_token(\"2vKYicHhJEE27Jf9VuGiFdieLqi_3ZVTehiUXXMBDs8xVy5BK\")\n",
        "\n",
        "# Kill any existing tunnels\n",
        "ngrok.kill()\n",
        "\n",
        "# Create a tunnel to the default Streamlit port 8501\n",
        "public_url = ngrok.connect(8501, proto=\"http\")\n",
        "print(\"Streamlit app public URL:\", public_url)"
      ],
      "metadata": {
        "id": "kZ3eHEhSQYst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cCnle-0UdWrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Finally, run this code block. Once it gives the message \"You can now view your Streamlit app in your browser\",\n",
        "#go back to the code block above and click the first link, and click Visit Link.\n",
        "#You will then be taken to the main page for MeetScribe.\n",
        "!streamlit run app.py & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "XvO4L3QjQZXl",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
