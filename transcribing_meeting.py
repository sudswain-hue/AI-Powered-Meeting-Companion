# -*- coding: utf-8 -*-
"""Transcribing Meeting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oOc5xWHeMC6fb28kIIwnbjUYbqfNIHV0
"""

!pip install -q git+https://github.com/openai/whisper.git

import whisper
from transformers import pipeline
import spacy

# Transcript Function

def transcript(audio_file):
  model = whisper.load_model("base")
  result = model.transcribe(audio_file)
  transcription_text = result["text"]
  # print("Detected Language:", result["language"]) # Check which language is the audio in
  transcription_text = result["text"]
  # print("Full Transcription:\n", transcription_text) # Transcript
  return transcription_text

audio_file = "company_meeting2.mp3"
transcription_text = transcript(audio_file)
print(transcription_text)

# Summarizer function

def summary(transcription_text):
  summarizer = pipeline("summarization", model="facebook/bart-large-cnn")
  summary = summarizer(transcription_text, max_length=150, min_length=80, do_sample=False)
  return summary[0]['summary_text']

summary_output = summary(transcription_text)
print(summary_output)

# Action Items Extractor

def action_items(transcription_text):
  # Process the transcript text with spaCy to break it into sentences
  nlp = spacy.load("en_core_web_sm")
  doc = nlp(transcription_text)
  action_keywords = ["please", "send", "review", "schedule", "complete", "update", "assign", "remind"]

  def is_action_item(sentence):
      """Return True if the sentence contains any action-related keywords."""
      return any(keyword in sentence.text.lower() for keyword in action_keywords)
  # Extract action items with potential owners and deadlines
  action_items_extracted = []
  for sent in doc.sents:
      if is_action_item(sent):
          # Use spaCy's Named Entity Recognition (NER) to capture PERSON, DATE, and TIME entities
          persons = [ent.text for ent in sent.ents if ent.label_ == "PERSON"]
          deadlines = [ent.text for ent in sent.ents if ent.label_ in ["DATE", "TIME"]]
          action_items_extracted.append({
              "task": sent.text.strip(),
              "owners": persons,
              "deadlines": deadlines
                              })

  return action_items_extracted

# Display the extracted action items
action_items_extracted = action_items(transcription_text)

for item in action_items_extracted:
    print("Task:", item["task"])
    print("Assigned To:", item["owners"])
    print("Deadlines:", item["deadlines"])
    print("-" * 50)

def sentiment_analysis(texts):

  # Load the sentiment classifier
  classifier = pipeline("sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment")

  # Define the mapping from star labels to sentiment
  def map_stars_to_sentiment(label):
      stars = int(label.split()[0])  # label format: '1 star', '5 stars', etc.
      if stars <= 2:
          return "negative"
      elif stars == 3:
          return "neutral"
      else:
          return "positive"

  for text in texts:
    result = classifier(text)[0]
    sentiment = map_stars_to_sentiment(result["label"])

  return result, sentiment

# Split the text by period and filter out any empty strings
texts = [sentence.strip() for sentence in transcription_text.split('.') if sentence.strip()]
print(texts)

result, sentiment = sentiment_analysis(texts)

for text in texts:
  print(f"Text: {text}")
  print(f"Sentiment: {sentiment} (Label: {result['label']}, Confidence: {result['score']:.2f})\n")